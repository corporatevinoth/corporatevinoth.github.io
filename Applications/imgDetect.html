<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Object Detection Demo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    html, body {
      margin: 0; padding: 0; height: 100%; width: 100%; overflow: hidden; background: #181818;
    }
    body {
      height: 100vh; width: 100vw; position: relative;
    }
    #video, #canvas {
      position: absolute; left: 0; top: 0; width: 100vw; height: 100vh; object-fit: cover;
    }
    #status {
      position: fixed; top: 12px; left: 50%; transform: translateX(-50%);
      background: rgba(0,0,0,0.7); color: #fff; z-index: 10; padding: 7px 24px; border-radius: 16px;
      font-size: 1.1rem; font-family: Arial,sans-serif; letter-spacing: 1px;
      text-align: center; pointer-events: none;
    }
    .home-btn {
      position: fixed; top: 12px; right: 12px; z-index: 11;
      background: rgba(0,0,0,0.7); color: #fff; border: 1px solid rgba(255,255,255,0.3); border-radius: 8px;
      padding: 8px 12px; text-decoration: none; font-size: 0.9em; transition: background-color 0.3s;
    }
    .home-btn:hover {
      background: rgba(0,0,0,0.9);
    }
    @media (max-width: 700px) {
      #status { font-size: 1em; padding: 5px 12px; }
      .home-btn { top: 8px; right: 8px; padding: 6px 10px; font-size: 0.8em; }
    }
  </style>
</head>
<body>
  <div id="status">Loading model...</div>
  <a href="../index.html" class="home-btn" title="Back to Home">üè† Home</a>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>
  <!-- TensorFlow.js and COCO-SSD -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <script>
    const statusDiv = document.getElementById('status');
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    let model = null;

    // Set up camera stream
    async function setupCamera() {
      try {
        // Request a modest resolution to keep inference fast on most devices
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: 'environment', width: { ideal: 640 }, height: { ideal: 480 } },
          audio: false
        });
        video.srcObject = stream;
        return new Promise(resolve => {
          video.onloadedmetadata = () => resolve(video);
        });
      } catch (e) {
        statusDiv.textContent = "Camera error: " + e.message;
        throw e;
      }
    }

    // Run detection loop with throttling to avoid blocking the main thread.
    let isDetecting = false;
    const detectIntervalMs = 250; // run model ~4x per second

    let lastPredictions = [];

    function drawFrame() {
      if (video.readyState === 4) {
        // Resize canvas if needed
        if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
        }
        // Draw current video frame
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        // Draw latest predictions (if any) on top of the video
        if (lastPredictions && lastPredictions.length) {
          ctx.lineWidth = 3;
          ctx.font = "18px Arial";
          lastPredictions.forEach(pred => {
            const [x, y, w, h] = pred.bbox;
            ctx.beginPath();
            ctx.strokeStyle = "#00ff66";
            ctx.rect(x, y, w, h);
            ctx.stroke();

            const label = pred.class + " " + Math.round(pred.score * 100) + "%";
            const textWidth = ctx.measureText(label).width;
            const labelX = x;
            const labelY = y > 20 ? y - 7 : y + 20;
            ctx.fillStyle = "rgba(0,0,0,0.6)";
            ctx.fillRect(labelX, labelY - 18, textWidth + 12, 22);
            ctx.fillStyle = "#fff";
            ctx.fillText(label, labelX + 6, labelY);
          });
        }
      }
      requestAnimationFrame(drawFrame);
    }

    async function runDetectionOnce() {
      if (!model || isDetecting || video.readyState !== 4) return;
      isDetecting = true;
      try {
        const predictions = await model.detect(video);
        lastPredictions = predictions || [];
        statusDiv.textContent = `Detected: ${lastPredictions.length} objects`;
      } catch (err) {
        console.error('Detection error', err);
        statusDiv.textContent = 'Detection error: ' + (err.message || err);
        lastPredictions = [];
      } finally {
        isDetecting = false;
      }
    }

    async function main() {
      statusDiv.textContent = "Starting camera...";
      await setupCamera();
      video.play();
      statusDiv.textContent = "Loading model...";
      model = await cocoSsd.load();
      statusDiv.textContent = "Model loaded! Point your camera at objects.";
      // Start continuous rendering of video frames
      drawFrame();

      // Start periodic detection at a modest rate to avoid blocking
      setInterval(runDetectionOnce, detectIntervalMs);
    }

    main();
  </script>
</body>
</html>
